---
phase: 11-discovery-steps-1-4
plan: 03
type: execute
wave: 2
depends_on: ["11-01", "11-02"]
files_modified:
  - src/lib/ai/prompts/step-prompts.ts
  - src/lib/schemas/step-schemas.ts
  - src/lib/ai/prompts/validation-criteria.ts
autonomous: false

must_haves:
  truths:
    - "User can start a workshop, complete Step 1, and see HMW artifact extracted"
    - "User can advance to Step 2, AI references Step 1 HMW in its greeting"
    - "User can complete all 4 Discovery steps sequentially with context flowing forward"
    - "Extracted artifacts match Zod schemas for all 4 steps"
  artifacts:
    - path: "src/lib/ai/prompts/step-prompts.ts"
      provides: "Finalized prompts for Steps 1-4 after integration testing"
    - path: "src/lib/schemas/step-schemas.ts"
      provides: "Validated schemas for Steps 1-4 that extract reliably"
  key_links:
    - from: "step-prompts.ts"
      to: "step-schemas.ts"
      via: "Prompts guide AI to produce outputs matching schema fields"
      pattern: "STEP GOAL"
    - from: "step-navigation.tsx"
      to: "generate-summary.ts"
      via: "advanceToNextStep triggers summary generation"
      pattern: "generateStepSummary"
---

<objective>
Integration test the end-to-end Discovery Steps flow and fix any issues found. Verify the complete pipeline: chat -> arc transitions -> extraction -> artifact save -> summary generation -> forward context.

Purpose: Plans 11-01 and 11-02 wire infrastructure and enrich prompts independently. This plan verifies they work together as a complete flow, and fixes any integration issues (schema mismatches, prompt-schema alignment, extraction failures).

Output: All 4 Discovery steps working end-to-end with human-verified quality.
</objective>

<execution_context>
@/Users/michaelchristie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/michaelchristie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-discovery-steps-1-4/11-01-SUMMARY.md
@.planning/phases/11-discovery-steps-1-4/11-02-SUMMARY.md
@src/lib/ai/prompts/step-prompts.ts
@src/lib/schemas/step-schemas.ts
@src/lib/ai/prompts/validation-criteria.ts
@src/app/api/chat/route.ts
@src/app/api/extract/route.ts
@src/lib/extraction/extract-artifact.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Verify build and schema-prompt alignment</name>
  <files>
    src/lib/ai/prompts/step-prompts.ts
    src/lib/schemas/step-schemas.ts
    src/lib/ai/prompts/validation-criteria.ts
  </files>
  <action>
Run a comprehensive verification of the complete pipeline:

1. Build verification:
   - Run `npx tsc --noEmit` to check for type errors
   - Run `npm run build` to verify production build

2. Schema-prompt alignment check for Steps 1-4:
   - For each step, verify that the prompt's GATHERING REQUIREMENTS mention every required field in the schema
   - Step 1 (challenge): prompt should guide toward problemStatement, targetUser, desiredOutcome, hmwStatement, altitude
   - Step 2 (stakeholder-mapping): prompt should guide toward stakeholders array with name, category, power, interest, notes
   - Step 3 (user-research): prompt should guide toward interviewQuestions array and insights array with finding, source, quote
   - Step 4 (sense-making): prompt should guide toward themes array (name + evidence), pains array, gains array
   - If any schema field is NOT mentioned in the prompt's gathering requirements, add a note in the relevant GATHERING REQUIREMENTS section

3. Verify validation criteria alignment:
   - Each validation criterion should map to a schema field or behavioral quality
   - Criteria should not reference fields that don't exist in the schema

4. Fix any misalignment issues found. Common fixes:
   - If prompt mentions fields not in schema: remove from prompt or add to schema (prefer removing from prompt)
   - If schema has fields prompt doesn't mention: add guidance to prompt's GATHERING REQUIREMENTS
   - If validation criteria reference non-existent aspects: update criteria

5. Run `npm run build` again after any fixes to confirm no regressions.
  </action>
  <verify>
- `npx tsc --noEmit` passes
- `npm run build` succeeds
- Each Step 1-4 prompt mentions all required schema fields in GATHERING REQUIREMENTS
- Each validation criterion maps to schema fields or observable behaviors
  </verify>
  <done>
Build passes, prompts and schemas aligned for Steps 1-4, validation criteria consistent with schema structure.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete Discovery Steps (1-4) AI facilitation pipeline with enriched prompts, arc phase transitions, summary generation, and structured extraction.</what-built>
  <how-to-verify>
1. Start the dev server: `npm run dev`
2. Navigate to the app and create a new workshop
3. **Step 1 (Challenge):**
   - Chat with AI about a test idea (e.g., "I want to help remote teams collaborate better")
   - Verify AI asks probing questions about the problem (not jumping to solutions)
   - Verify AI drafts HMW variants at different altitudes
   - Click "Extract Output" and verify the artifact renders with problemStatement, targetUser, hmwStatement
   - Confirm artifact and click Next

4. **Step 2 (Stakeholder Mapping):**
   - Verify AI references Step 1 HMW in its opening (forward context working)
   - Verify AI helps brainstorm stakeholders and proactively asks about missing categories
   - Extract and verify stakeholder list with Core/Direct/Indirect categories
   - Confirm and advance

5. **Step 3 (User Research):**
   - Verify AI references challenge and stakeholder map
   - Verify AI generates interview questions and facilitates synthetic interviews
   - Verify insights have source attribution (which stakeholder said what)
   - Extract and confirm

6. **Step 4 (Sense Making):**
   - Verify AI references Step 3 research findings
   - Verify AI clusters into themes with evidence
   - Verify pains/gains trace to specific research findings (not generic)
   - Extract and confirm

7. Check that arc phases appear to transition (AI behavior shifts from introductory to gathering to synthesizing across the conversation)
  </how-to-verify>
  <resume-signal>Type "approved" if Steps 1-4 work end-to-end, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
1. Build passes (`npm run build`)
2. Schema-prompt alignment verified for all 4 Discovery steps
3. Human verification of end-to-end flow for Steps 1-4
4. Forward context flows between steps (Step 2 AI knows Step 1 output)
5. Arc phase transitions produce observable behavior changes
</verification>

<success_criteria>
- User completes Steps 1-4 with AI facilitation that builds on prior context
- Extracted artifacts match Zod schemas and contain meaningful data
- AI behavior shifts across the conversational arc (not stuck in orient)
- Forward context verified: Step 4 AI references Step 3 findings
- Human approves end-to-end quality
</success_criteria>

<output>
After completion, create `.planning/phases/11-discovery-steps-1-4/11-03-SUMMARY.md`
</output>
