---
phase: 14-production-hardening
plan: 02
type: execute
wave: 2
depends_on: ["14-01"]
files_modified:
  - src/components/workshop/chat-panel.tsx
autonomous: false

must_haves:
  truths:
    - "User sees 'AI is busy, retrying...' feedback when rate limited instead of silent spinner"
    - "User sees 'Response interrupted' with Retry button when streaming fails"
    - "User can click Retry to regenerate the last AI response without refreshing the page"
    - "Rate limit countdown timer counts down from retryAfter seconds"
    - "Chat input is disabled during rate limit cooldown"
    - "Stream timeout detection shows recovery UI after 30s of no new content during streaming"
  artifacts:
    - path: "src/components/workshop/chat-panel.tsx"
      provides: "Rate limit feedback UI, streaming error recovery, retry button"
      contains: "rate_limit_exceeded"
  key_links:
    - from: "src/components/workshop/chat-panel.tsx"
      to: "/api/chat"
      via: "useChat onError callback parsing 429 responses"
      pattern: "rate_limit_exceeded"
    - from: "src/components/workshop/chat-panel.tsx"
      to: "useChat reload"
      via: "Retry button onClick calling reload()"
      pattern: "reload"
---

<objective>
Client-side error handling for rate limits and streaming interruptions

Purpose: Users need to understand what's happening when the AI is unavailable (rate limited) or when streaming breaks. Silent failures destroy trust. This plan adds visible feedback during retries, a countdown timer for rate limits, and a "Retry" button for interrupted streams.

Output: Updated chat-panel.tsx with rate limit banner, streaming error recovery, and retry functionality
</objective>

<execution_context>
@/Users/michaelchristie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/michaelchristie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-production-hardening/14-RESEARCH.md
@.planning/phases/14-production-hardening/14-01-SUMMARY.md
@src/components/workshop/chat-panel.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add rate limit feedback and streaming error recovery to ChatPanel</name>
  <files>src/components/workshop/chat-panel.tsx</files>
  <action>
Modify `src/components/workshop/chat-panel.tsx` to handle two error states: rate limiting (429) and stream interruption.

1. **Add error state management:**
   - Add state: `const [rateLimitInfo, setRateLimitInfo] = useState<{ retryAfter: number } | null>(null)`
   - Add state: `const [streamError, setStreamError] = useState(false)`
   - Add ref for countdown interval: `const countdownRef = useRef<NodeJS.Timeout | null>(null)`

2. **Handle rate limit errors from useChat:**
   The current `useChat` hook uses `DefaultChatTransport`. When the chat API returns a 429, the transport will throw an error. We need to detect this.

   Add `onError` callback to the `useChat` hook configuration:
   ```typescript
   const { messages, sendMessage, status, reload } = useChat({
     transport,
     messages: initialMessages,
     onError: (error) => {
       // Check if this is a rate limit error from our API
       // The error message from DefaultChatTransport may contain the response body
       const errorStr = error?.message || '';
       if (errorStr.includes('rate_limit_exceeded') || errorStr.includes('429')) {
         // Parse retryAfter from error if possible, default to 30s
         let retryAfter = 30;
         try {
           const parsed = JSON.parse(errorStr);
           if (parsed.retryAfter) retryAfter = parsed.retryAfter;
         } catch {
           // Use default
         }

         setRateLimitInfo({ retryAfter });

         // Start countdown
         if (countdownRef.current) clearInterval(countdownRef.current);
         countdownRef.current = setInterval(() => {
           setRateLimitInfo((prev) => {
             if (!prev || prev.retryAfter <= 1) {
               if (countdownRef.current) clearInterval(countdownRef.current);
               return null;
             }
             return { retryAfter: prev.retryAfter - 1 };
           });
         }, 1000);
       } else {
         // Non-rate-limit streaming error
         setStreamError(true);
       }
     },
   });
   ```

   IMPORTANT: Also destructure `reload` from useChat — this is the function that retries the last message.

3. **Add stream timeout detection:**
   Add a useEffect that monitors streaming state. If `status === 'streaming'` for 30+ seconds with no new messages, set streamError to true.
   ```typescript
   useEffect(() => {
     if (status !== 'streaming') return;
     const timeout = setTimeout(() => {
       setStreamError(true);
     }, 30000);
     return () => clearTimeout(timeout);
   }, [status, messages.length]); // Reset timer when new message content arrives
   ```

4. **Clear errors on successful completion:**
   Add a useEffect: when `status` transitions to `'ready'`, clear both error states:
   ```typescript
   useEffect(() => {
     if (status === 'ready') {
       setStreamError(false);
       // Don't clear rateLimitInfo here — let the countdown finish
     }
   }, [status]);
   ```

5. **Render rate limit banner (above the input area, below messages):**
   When `rateLimitInfo` is set, show a yellow-tinted alert:
   ```
   <div className="mx-4 mb-2 flex items-center gap-2 rounded-md border border-yellow-500/50 bg-yellow-50 dark:bg-yellow-950/20 px-3 py-2 text-sm text-yellow-800 dark:text-yellow-200">
     <Loader2 className="h-4 w-4 animate-spin shrink-0" />
     <span>AI is busy. Try again in {rateLimitInfo.retryAfter}s...</span>
   </div>
   ```
   Import `Loader2` from `lucide-react` (already imported as `Send` — add Loader2 to the existing import).

6. **Render stream error recovery (inline, after last message):**
   When `streamError` is true and `status !== 'streaming'`, show recovery UI after the last message:
   ```
   <div className="flex items-start gap-3">
     <div className="flex size-8 shrink-0 items-center justify-center rounded-full bg-primary text-primary-foreground">AI</div>
     <div className="flex-1">
       <div className="rounded-lg border border-yellow-500/50 bg-yellow-50 dark:bg-yellow-950/20 p-3 text-sm">
         <p className="text-yellow-800 dark:text-yellow-200">Response was interrupted.</p>
         <Button
           onClick={() => { setStreamError(false); reload(); }}
           variant="outline"
           size="sm"
           className="mt-2"
         >
           Retry Response
         </Button>
       </div>
     </div>
   </div>
   ```
   Place this inside the messages area, after the typing indicator block, before the auto-scroll target div.

7. **Disable input during rate limit:**
   Update the textarea `disabled` prop: `disabled={isLoading || !!rateLimitInfo}`
   Update the send button `disabled` prop: `disabled={isLoading || !inputValue.trim() || !!rateLimitInfo}`
   Update placeholder when rate limited: `rateLimitInfo ? 'Waiting for AI to become available...' : 'Type your message...'`

8. **Cleanup countdown on unmount:**
   Add useEffect cleanup:
   ```typescript
   useEffect(() => {
     return () => {
       if (countdownRef.current) clearInterval(countdownRef.current);
     };
   }, []);
   ```

DO NOT restructure the existing message rendering logic, auto-start, auto-scroll, suggestion pills, or auto-save. Only ADD the error handling layer on top.
  </action>
  <verify>
    - `npm run build` passes (no TypeScript errors)
    - `grep -c "rate_limit_exceeded" src/components/workshop/chat-panel.tsx` returns at least 1
    - `grep -c "streamError" src/components/workshop/chat-panel.tsx` returns at least 1
    - `grep -c "reload" src/components/workshop/chat-panel.tsx` returns at least 1
    - `grep -c "Retry Response" src/components/workshop/chat-panel.tsx` returns 1
  </verify>
  <done>
    ChatPanel detects rate limit (429) errors and shows countdown banner with seconds remaining. ChatPanel detects stream interruptions (onError + 30s timeout) and shows "Retry Response" button. Input is disabled during rate limit cooldown. Retry button calls useChat's reload() to re-attempt last message without page refresh.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Complete production hardening for Phase 14:
    1. Rate limit retry with exponential backoff on all Gemini API calls (chat, extraction, summary)
    2. Health check cron warming every 4 minutes (vercel.json + authenticated /api/health)
    3. Rate limit feedback UI in chat (countdown timer when 429 occurs)
    4. Streaming error recovery UI (Retry Response button on interrupted streams)
  </what-built>
  <how-to-verify>
    1. Run `npm run dev` and open http://localhost:3000
    2. Start a workshop, navigate to any step, and verify chat still works normally (no regressions)
    3. To test rate limit UI: Temporarily modify `src/lib/ai/gemini-retry.ts` to always throw a 429-like error on first attempt, observe the chat panel shows yellow "AI is busy" banner (then revert the change)
    4. To test stream error recovery: While AI is streaming, quickly close your laptop lid or disable network briefly — on reconnect, you should see "Response was interrupted" with a Retry button
    5. Verify health endpoint: `curl http://localhost:3000/api/health` returns 200 (no CRON_SECRET in dev, so unauthenticated works)
    6. Verify vercel.json exists at project root with cron config
    7. Verify `npm run build` succeeds cleanly
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
1. `npm run build` passes with zero TypeScript errors
2. Rate limit banner appears when API returns 429
3. Countdown timer decrements every second
4. Chat input disabled during rate limit cooldown
5. Stream error shows "Retry Response" button
6. Retry button re-sends last message (uses reload())
7. Normal chat flow unaffected (no regressions)
8. Health endpoint returns 200 without auth in dev, 401 without auth when CRON_SECRET set
</verification>

<success_criteria>
- Rate limit feedback visible to user (not silent failure)
- Streaming interruption shows recovery path (Retry button)
- Input disabled during rate limit cooldown with explanatory placeholder
- Countdown timer counts down from retryAfter value
- All existing chat functionality preserved (auto-start, suggestions, auto-save, markdown rendering)
</success_criteria>

<output>
After completion, create `.planning/phases/14-production-hardening/14-02-SUMMARY.md`
</output>
