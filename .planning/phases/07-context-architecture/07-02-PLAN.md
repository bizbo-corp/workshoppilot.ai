---
phase: 07-context-architecture
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - src/lib/context/assemble-context.ts
  - src/lib/context/generate-summary.ts
  - src/lib/context/save-artifact.ts
autonomous: true

must_haves:
  truths:
    - "assembleStepContext returns three-tier context (persistent artifacts, long-term summaries, short-term messages)"
    - "generateStepSummary produces a 150-word bullet-point summary from conversation history"
    - "saveStepArtifact writes JSONB artifact with optimistic locking"
    - "Context assembly queries database for all prior step artifacts and summaries"
  artifacts:
    - path: "src/lib/context/assemble-context.ts"
      provides: "Three-tier context assembly function"
      exports: ["assembleStepContext"]
    - path: "src/lib/context/generate-summary.ts"
      provides: "AI-powered conversation summarization"
      exports: ["generateStepSummary"]
    - path: "src/lib/context/save-artifact.ts"
      provides: "Artifact persistence with optimistic locking"
      exports: ["saveStepArtifact"]
  key_links:
    - from: "src/lib/context/assemble-context.ts"
      to: "src/db/schema/step-artifacts.ts"
      via: "Drizzle query for all artifacts"
      pattern: "stepArtifacts"
    - from: "src/lib/context/assemble-context.ts"
      to: "src/db/schema/step-summaries.ts"
      via: "Drizzle query for previous summaries"
      pattern: "stepSummaries"
    - from: "src/lib/context/assemble-context.ts"
      to: "src/db/schema/chat-messages.ts"
      via: "Drizzle query for current step messages"
      pattern: "chatMessages"
    - from: "src/lib/context/generate-summary.ts"
      to: "@ai-sdk/google"
      via: "generateText call for summarization"
      pattern: "generateText"
    - from: "src/lib/context/save-artifact.ts"
      to: "src/db/schema/step-artifacts.ts"
      via: "Drizzle insert/update with version check"
      pattern: "stepArtifacts"
---

<objective>
Build the three core context service functions: assembleStepContext (reads three-tier context from database), generateStepSummary (creates AI-powered conversation summaries), and saveStepArtifact (persists structured JSON artifacts with optimistic locking).

Purpose: These are the engine of the dual-layer context architecture. assembleStepContext is called on every AI request to inject prior step knowledge. generateStepSummary is called on step completion to create the long-term memory tier. saveStepArtifact is called during structured extraction to persist the persistent memory tier.

Output: Three service functions in src/lib/context/ that are ready to be wired into the chat API route and step completion flow (Plan 03).
</objective>

<execution_context>
@/Users/michaelchristie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/michaelchristie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/07-context-architecture/07-RESEARCH.md
@.planning/phases/07-context-architecture/07-01-SUMMARY.md

@src/db/client.ts
@src/db/schema/step-artifacts.ts
@src/db/schema/step-summaries.ts
@src/db/schema/chat-messages.ts
@src/db/schema/steps.ts
@src/db/schema/sessions.ts
@src/lib/context/types.ts
@src/lib/ai/chat-config.ts
@src/lib/ai/message-persistence.ts
@src/lib/workshop/step-metadata.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create assembleStepContext function</name>
  <files>src/lib/context/assemble-context.ts</files>
  <action>
Create the three-tier context assembly function that gathers all prior knowledge for an AI request.

**Function signature:**
```typescript
async function assembleStepContext(
  workshopId: string,
  currentStepId: string,
  sessionId: string
): Promise<StepContext>
```

**Implementation:**

1. **Tier 1 - Persistent Memory (all structured artifacts):**
   - Query stepArtifacts joined with workshopSteps where workshopSteps.workshopId = workshopId
   - Order by workshopSteps step order (join with stepDefinitions to get order, or use the STEPS array from step-metadata.ts to sort client-side)
   - Format each as: `"Step {stepName} ({stepId}): {JSON.stringify(artifact)}"`
   - Join with double newlines
   - If no artifacts exist, return empty string (not "No artifacts found" — don't waste tokens)

2. **Tier 2 - Long-term Memory (previous step summaries):**
   - Query stepSummaries joined with workshopSteps where workshopSteps.workshopId = workshopId AND stepSummaries.stepId != currentStepId
   - Order by step order (same approach as Tier 1)
   - Format each as: `"Step {stepName} ({stepId}): {summary}"`
   - Join with double newlines
   - If no summaries exist, return empty string

3. **Tier 3 - Short-term Memory (current step messages verbatim):**
   - Query chatMessages where sessionId = sessionId AND stepId = currentStepId
   - Order by createdAt ascending
   - Map to array of { role, content } objects
   - These become the `messages` array passed to streamText

**Return:** StepContext object with persistentContext, summaries, and messages fields.

**Important patterns:**
- Use `db.select()` with joins (NOT db.query relational API) since we need cross-table joins
- Import eq, and, ne, asc from 'drizzle-orm'
- Import db from '@/db/client'
- Use the STEPS array from '@/lib/workshop/step-metadata' to resolve stepId -> stepName for formatting
- Use getStepById() to look up display names

**Performance note:** This function runs on EVERY chat request. Keep queries efficient. The join approach (2-3 queries) is fine since these tables are small (max 10 rows per workshop for artifacts/summaries).
  </action>
  <verify>
Run `npx tsc --noEmit` — TypeScript compilation succeeds.
Manually verify the function imports all required dependencies and returns the correct StepContext type.
  </verify>
  <done>assembleStepContext function exists, queries all three memory tiers from database, formats context strings, and returns typed StepContext object.</done>
</task>

<task type="auto">
  <name>Task 2: Create generateStepSummary and saveStepArtifact functions</name>
  <files>
    src/lib/context/generate-summary.ts
    src/lib/context/save-artifact.ts
  </files>
  <action>
**src/lib/context/generate-summary.ts:**

Create function to generate AI-powered conversation summaries on step completion.

```typescript
async function generateStepSummary(
  sessionId: string,
  workshopStepId: string,
  stepId: string,
  stepName: string
): Promise<string>
```

Implementation:
1. Load all messages for this session+step from chatMessages using the same query pattern as loadMessages() in message-persistence.ts
2. Format messages as conversation text: `"{role}: {content}"` joined with newlines
3. Call generateText (NOT streamText — we don't need streaming for background summarization) from 'ai' package:
   - model: google('gemini-2.0-flash') — same model as chat, imported from @ai-sdk/google
   - prompt: Use the INSTRUCTIONS/CONSTRAINTS/OUTPUT FORMAT pattern from research:
     ```
     INSTRUCTIONS:
     Summarize the following conversation from Step {stepName} in 3-4 bullet points.
     Focus on: (1) key decisions made, (2) user's specific inputs, (3) final outputs produced.
     Use clear, concise language. Do NOT include conversational pleasantries.

     CONSTRAINTS:
     - Maximum 150 words
     - Bullet point format (use - prefix)
     - Factual only, no interpretation
     - Reference specific values (names, numbers, quotes the user provided)

     OUTPUT FORMAT:
     - Bullet point 1
     - Bullet point 2
     - Bullet point 3

     CONVERSATION:
     {formattedConversation}
     ```
   - temperature: 0.1 (low for factual accuracy)
4. Save summary to step_summaries table: insert with workshopStepId, stepId, summary text, and optionally tokenCount from usage.totalTokens
5. Return the summary text

**Error handling:** Wrap in try/catch. If AI summarization fails, save a fallback summary: "Step {stepName} completed. Summary generation failed — conversation history preserved in messages." Log the error. Do NOT throw — summary failure should not block step completion.

**src/lib/context/save-artifact.ts:**

Create function to persist structured JSON artifacts with optimistic locking.

```typescript
async function saveStepArtifact(
  workshopStepId: string,
  stepId: string,
  artifact: Record<string, unknown>,
  schemaVersion?: string
): Promise<void>
```

Implementation:
1. Try to find existing artifact for this workshopStepId
2. If exists: Update with version check (optimistic locking):
   - Read current version
   - Update where id matches AND version matches current
   - If rowCount is 0, throw OptimisticLockError (another request updated it)
   - Increment version
3. If not exists: Insert new artifact with version 1
4. Use upsert pattern with onConflictDoUpdate if Drizzle supports it cleanly, otherwise use the read-check-write pattern in a transaction

**Important:** Import generateText from 'ai' (NOT from '@ai-sdk/google'). Import google from '@ai-sdk/google'. This matches the pattern in the research doc and AI SDK conventions.

**Do NOT use the deprecated generateObject() or streamObject()** — these are replaced by streamText with output property in AI SDK 6, but for plain text summarization, generateText is correct.

Create an index.ts barrel file at src/lib/context/index.ts that re-exports all public functions from the three service files.
  </action>
  <verify>
Run `npx tsc --noEmit` — TypeScript compilation succeeds.
Verify generate-summary.ts imports generateText from 'ai' and google from '@ai-sdk/google'.
Verify save-artifact.ts has optimistic locking logic (version check in update).
  </verify>
  <done>generateStepSummary produces AI summaries with 150-word bullet-point format and saves to database. saveStepArtifact persists JSONB artifacts with optimistic locking. Both handle errors gracefully. Barrel index exports all public functions.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no errors
2. assembleStepContext queries all three tiers and returns StepContext
3. generateStepSummary uses generateText with low temperature and structured prompt
4. saveStepArtifact implements optimistic locking with version column
5. All functions use existing db client and schema imports
</verification>

<success_criteria>
- Three service functions exist and compile without errors
- assembleStepContext returns persistent context, summaries, and messages from database
- generateStepSummary creates 150-word bullet-point summaries via Gemini
- saveStepArtifact writes artifacts with version-based optimistic locking
- Error handling is graceful (no unhandled throws that could crash the server)
</success_criteria>

<output>
After completion, create `.planning/phases/07-context-architecture/07-02-SUMMARY.md`
</output>
